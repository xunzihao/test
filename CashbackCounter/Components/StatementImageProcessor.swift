//
//  StatementImageProcessor.swift
//  CashbackCounter
//
//  Created by Assistant on 12/20/25.
//

import UIKit
import Vision
import CoreImage
import CoreImage.CIFilterBuiltins

/// è´Ÿè´£å¤„ç†è´¦å•å›¾ç‰‡çš„å·¥å…·ç±»ï¼ˆè£å‰ªã€è¾¹ç¼˜æ£€æµ‹ã€OCRå®šä½ï¼‰
struct StatementImageProcessor {
    
    /// ğŸ”ª è£å‰ªäº¤æ˜“è¡¨æ ¼åŒºåŸŸï¼ˆåŸºäºè¾¹ç¼˜æ£€æµ‹å’Œ OCR å®šä½ï¼‰
    static func cropTransactionTable(from image: UIImage) -> UIImage {
        guard let cgImage = image.cgImage else { return image }
        
        // åŸºäº OCR å…³é”®å­—å®šä½
        if let ocrBasedRect = detectTableByOCR(in: image) {
            if let croppedCGImage = cgImage.cropping(to: ocrBasedRect) {
                print("âœ… é€šè¿‡ OCR å®šä½è¡¨æ ¼: \(ocrBasedRect)")
                return UIImage(cgImage: croppedCGImage, scale: image.scale, orientation: image.imageOrientation)
            }
        }
        
        // å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›åŸå›¾
        print("âš ï¸ æœªèƒ½æ£€æµ‹åˆ°è¡¨æ ¼è¾¹æ¡†ï¼Œä½¿ç”¨åŸå›¾")
        return image
    }
    
    /// ğŸ” åŸºäº OCR å…³é”®å­—å®šä½è¡¨æ ¼
    static func detectTableByOCR(in image: UIImage) -> CGRect? {
        guard let cgImage = image.cgImage else { return nil }
        
        let semaphore = DispatchSemaphore(value: 0)
        var detectedRect: CGRect?
        
        let request = VNRecognizeTextRequest { request, error in
            defer { semaphore.signal() }
            
            guard let observations = request.results as? [VNRecognizedTextObservation] else { return }
            
            // æŸ¥æ‰¾è¡¨æ ¼çš„å…³é”®æ ‡è®°
            var headerY: CGFloat?
            var footerY: CGFloat?
            var minX: CGFloat = 1.0
            var maxX: CGFloat = 0.0
            
            print("ğŸ” å¼€å§‹ OCR å®šä½ï¼Œå…± \(observations.count) ä¸ªæ–‡æœ¬å—")
            
            for observation in observations {
                guard let text = observation.topCandidates(1).first?.string else { continue }
                let textUpper = text.uppercased()
                let box = observation.boundingBox
                
                // ğŸ†• æŸ¥æ‰¾è¡¨å¤´ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
                if (textUpper.contains(AppConstants.OCR.headerKeywords[0]) && textUpper.contains(AppConstants.OCR.headerKeywords[2])) ||
                   (textUpper.contains(AppConstants.OCR.headerKeywords[1]) && textUpper.contains(AppConstants.OCR.headerKeywords[2])) ||
                   textUpper.contains(AppConstants.OCR.headerKeywords[3]) {
                    print("âœ… æ‰¾åˆ°è¡¨å¤´: '\(text)' at Y=\(box.minY)")
                    if headerY == nil || box.minY < headerY! {
                        headerY = box.minY  // ä½¿ç”¨æœ€ä¸Šé¢çš„è¡¨å¤´
                    }
                }
                
                // ğŸ†• æŸ¥æ‰¾ "Note" æˆ– "REWARDCASH" ä½œä¸ºè¡¨å°¾
                if (textUpper.contains(AppConstants.OCR.footerKeywords[0]) && textUpper.contains(AppConstants.OCR.footerKeywords[1])) ||
                   textUpper.contains(AppConstants.OCR.footerKeywords[2]) {
                    print("âœ… æ‰¾åˆ°è¡¨å°¾æ ‡è®°: '\(text)' at Y=\(box.maxY)")
                    if footerY == nil || box.maxY < footerY! {
                        footerY = box.maxY
                    }
                }
                
                // è®°å½•æ‰€æœ‰æ–‡æœ¬çš„è¾¹ç•Œï¼ˆæ’é™¤æ˜æ˜¾çš„æ ‡é¢˜ï¼‰
                if !textUpper.contains(AppConstants.OCR.ignoreKeywords[0]) &&
                   !textUpper.contains(AppConstants.OCR.ignoreKeywords[1]) &&
                   !textUpper.contains(AppConstants.OCR.ignoreKeywords[2]) {
                    minX = min(minX, box.minX)
                    maxX = max(maxX, box.maxX)
                }
            }
            
            print("ğŸ“Š æ£€æµ‹ç»“æœ: headerY=\(headerY ?? -1), footerY=\(footerY ?? -1)")
            
            // å¦‚æœæ‰¾åˆ°äº†è¡¨å¤´ï¼Œæ„å»ºçŸ©å½¢
            if let header = headerY {
                let width = CGFloat(cgImage.width)
                let height = CGFloat(cgImage.height)
                
                // è½¬æ¢ä¸º CGImage åæ ‡ç³»ï¼ˆåŸç‚¹åœ¨å·¦ä¸Šè§’ï¼‰
                let top = height * (1 - header) - 20  // ğŸ†• ç¨å¾®å‘ä¸Šæ‰©å±• 20pxï¼Œç¡®ä¿åŒ…å«è¡¨å¤´
                
                // ğŸ†• è¡¨å°¾å¤„ç†
                let bottom: CGFloat
                if let footer = footerY {
                    bottom = height * (1 - footer) + 20  // å‘ä¸‹æ‰©å±• 20px
                    print("âœ… ä½¿ç”¨æ£€æµ‹åˆ°çš„è¡¨å°¾")
                } else {
                    bottom = height * 0.98  // ğŸ†• æ”¹ä¸º 98%ï¼Œå‡ ä¹åˆ°åº•éƒ¨
                    print("âš ï¸ æœªæ£€æµ‹åˆ°è¡¨å°¾ï¼Œä½¿ç”¨å›¾ç‰‡åº•éƒ¨")
                }
                
                let left = width * max(0, minX - 0.05)   // ğŸ†• å¢åŠ å·¦è¾¹è·åˆ° 5%
                let right = width * min(1, maxX + 0.05)  // ğŸ†• å¢åŠ å³è¾¹è·åˆ° 5%
                
                let rect = CGRect(x: left, y: top, width: right - left, height: bottom - top)
                print("âœ… OCR å®šä½æˆåŠŸ: \(rect)")
                detectedRect = rect
            } else {
                print("âŒ æœªæ‰¾åˆ°è¡¨å¤´ï¼ŒOCR å®šä½å¤±è´¥")
            }
        }
        
        request.recognitionLanguages = AppConstants.OCR.supportedLanguages
        request.recognitionLevel = .fast  // ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œåªéœ€è¦å®šä½
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        do {
            try handler.perform([request])
            semaphore.wait()  // ç­‰å¾… OCR å®Œæˆ
        } catch {
            print("âŒ OCR å®šä½å¤±è´¥: \(error)")
        }
        
        return detectedRect
    }
    
    // âš ï¸ detectTableBorder å’Œ findLargestRectangle æš‚æ—¶ä¸éœ€è¦æš´éœ²ï¼Œ
    // å› ä¸ºç›®å‰ cropTransactionTable åªä½¿ç”¨äº† OCR æ–¹æ³•ã€‚
    // å¦‚æœå°†æ¥éœ€è¦æ··åˆä½¿ç”¨ï¼Œå¯ä»¥å°†å®ƒä»¬ä½œä¸ºç§æœ‰æ–¹æ³•ç§»å…¥æ­¤å¤„ã€‚
}
